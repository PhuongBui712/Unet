{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "897bb531c6956ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-26T04:13:08.923453Z",
     "start_time": "2024-06-26T04:13:07.505872Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from typing import Literal\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457d376c52b0ea8a",
   "metadata": {},
   "source": [
    "## Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50aaa79c7c713a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BCSSDataset(Dataset):\n",
    "    SIZE=(224, 224)\n",
    "    def __init__(self, path: str, split: Literal['train', 'val', 'test'] = 'train'):\n",
    "        path = os.path.abspath(path)\n",
    "        image_path = os.path.join(path, split)\n",
    "        self.images = [os.path.join(image_path, filename) for filename in os.listdir(image_path)]\n",
    "        mask_path = os.path.join(path, f'{split}_mask')\n",
    "        self.masks = [os.path.join(mask_path, filename) for filename in os.listdir(mask_path)]\n",
    "\n",
    "        self.transformer = transforms.Compose([\n",
    "            transforms.Resize(self.SIZE),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "        # TODO: handle test set\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.images[idx])\n",
    "        mask = Image.open(self.masks[idx]).convert('L')\n",
    "\n",
    "        return self.transformer(image), self.transformer(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a33a28e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/bcss'\n",
    "train_split = BCSSDataset(data_path, 'train')\n",
    "val_split = BCSSDataset(data_path, 'val')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89c57b2",
   "metadata": {},
   "source": [
    "## Define Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8eb480da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 mid_channels: int = None,\n",
    "                 kernel_size: int = 2,\n",
    "                 stride: int = 1,\n",
    "                 padding: int = 0):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        mid_channels = mid_channels or out_channels\n",
    "        self.conv_ops = nn.Sequential(\n",
    "            # first \n",
    "            nn.Conv2d(in_channels=in_channels,\n",
    "                      out_channels=mid_channels,\n",
    "                      kernel_size=kernel_size,\n",
    "                      padding=padding,\n",
    "                      stride=stride),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(num_features=mid_channels),\n",
    "\n",
    "            # second\n",
    "            nn.Conv2d(in_channels=mid_channels,\n",
    "                      out_channels=out_channels,\n",
    "                      kernel_size=kernel_size,\n",
    "                      padding=padding,\n",
    "                      stride=stride),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(num_features=out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.conv_ops(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f486c205",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownSample(nn.Module):\n",
    "    def __init__(self,\n",
    "                 kernel_size: int = 2,\n",
    "                 stride: int = 1,\n",
    "                 padding: int = 0):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(kernel_size, stride, padding)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.pool(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a96aadde",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpSample(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 kernel_size: int = 2,\n",
    "                 stride: int = 1,\n",
    "                 padding: int = 0):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.up_conv = nn.ConvTranspose2d(in_channels=in_channels,\n",
    "                                          out_channels=out_channels,\n",
    "                                          kernel_size=kernel_size,\n",
    "                                          stride=stride,\n",
    "                                          padding=padding)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.up_conv(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb1076b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CropAndConcat(nn.Module):\n",
    "    def forward(self, X, contracting_X):\n",
    "        contracting_X = transforms.functional.center_crop(\n",
    "            img=contracting_X,\n",
    "            output_size=(X.shape[2], X.shape[3])\n",
    "        )\n",
    "        X = torch.cat((X, contracting_X), dim=1)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7df0a43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet(nn.Module):\n",
    "    # TODO: Customize the conv blocks for easy-scalable\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 output_classes: int,\n",
    "                 down_conv_kwargs: dict = None,\n",
    "                 down_sample_kwargs: dict = None,\n",
    "                 up_conv_kwargs: dict = None,\n",
    "                 up_sample_kwargs: dict = None,\n",
    "                 expansive_kwargs: dict = None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.down_conv = nn.ModuleList([\n",
    "            DoubleConv(in_channels=i, out_channels=o, **(down_conv_kwargs or {})) for i, o in ((in_channels, 64), (64, 128), (128, 256), (256, 512))\n",
    "        ])\n",
    "\n",
    "        self.down_sample = nn.ModuleList([\n",
    "            DownSample(**(down_sample_kwargs or {})) for _ in range(4)\n",
    "        ])\n",
    "\n",
    "        self.up_conv = nn.ModuleList([\n",
    "            DoubleConv(in_channels=i, out_channels=o, **(up_conv_kwargs or {})) for i, o in ((1024, 512), (512, 256), (256, 128), (128, 64))\n",
    "        ])\n",
    "\n",
    "        self.up_sample = nn.ModuleList([\n",
    "            UpSample(in_channels=i, out_channels=o, **(up_sample_kwargs or {})) for i, o in ((1024, 512), (512, 256), (256, 128), (128, 64))\n",
    "        ])\n",
    "\n",
    "        self.crop_concat = nn.ModuleList([CropAndConcat() for _ in range(4)])\n",
    "\n",
    "        self.bottlekneck = DoubleConv(in_channels=512,\n",
    "                                      out_channels=1024,\n",
    "                                      **(up_conv_kwargs or {}))\n",
    "        \n",
    "        self.output = nn.Conv2d(in_channels=64, out_channels=output_classes, kernel_size=1)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        pass_through = []\n",
    "        for i in range(len(self.down_conv)):\n",
    "            X = self.down_conv[i](X)\n",
    "            pass_through = [X] + pass_through\n",
    "            X = self.down_sample[i](X)\n",
    "\n",
    "        X = self.bottlekneck(X)\n",
    "\n",
    "        for i in range(len(self.up_conv)):\n",
    "            X = self.up_sample[i](X)\n",
    "            X = self.crop_concat[i](X, pass_through[i])\n",
    "            print(X.shape)\n",
    "            X = self.up_conv[i](X)\n",
    "\n",
    "        X = self.output(X)\n",
    "\n",
    "        return X"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
